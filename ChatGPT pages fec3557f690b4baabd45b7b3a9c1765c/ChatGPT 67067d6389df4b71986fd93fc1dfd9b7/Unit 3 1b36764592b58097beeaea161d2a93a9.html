<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Unit 3</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: undefined; }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-transparentGray { background-color: undefined; }
.select-value-color-translucentGray { background-color: undefined; }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1b367645-92b5-8097-beea-ea161d2a93a9" class="page sans"><header><h1 class="page-title">Unit 3</h1><p class="page-description"></p><table class="properties"><tbody><tr class="property-row property-row-relation"><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesRelation"><path d="M13.1475 10.5869V3.72363C13.1475 3.25195 12.833 2.93066 12.3477 2.93066H5.48438C5.02637 2.93066 4.70508 3.27246 4.70508 3.67578C4.70508 4.07227 5.05371 4.40039 5.46387 4.40039H7.89746L10.8438 4.30469L9.59961 5.39844L3.08496 11.9199C2.92773 12.0771 2.8457 12.2686 2.8457 12.46C2.8457 12.8564 3.20801 13.2256 3.61816 13.2256C3.80957 13.2256 3.99414 13.1504 4.15137 12.9932L10.6729 6.47168L11.7803 5.22754L11.6641 8.05762V10.6074C11.6641 11.0176 11.9922 11.373 12.4023 11.373C12.8057 11.373 13.1475 11.0312 13.1475 10.5869Z"></path></svg></span>Courses</th><td><a href="../../Databases%20938301ab80894adb89b438b270c6b180/Courses%20e0d6a8f12b2d4818ac8b1af662193ea9/Machine%20Learning%206629f04159a44bf48e528e1bb173e41c.html"><img class="icon" src="https://www.notion.so/icons/coffee-maker_gray.svg"/>Machine Learning</a></td></tr><tr class="property-row property-row-multi_select"><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesMultipleSelect"><path d="M1.91602 4.83789C2.44238 4.83789 2.87305 4.40723 2.87305 3.87402C2.87305 3.34766 2.44238 2.91699 1.91602 2.91699C1.38281 2.91699 0.952148 3.34766 0.952148 3.87402C0.952148 4.40723 1.38281 4.83789 1.91602 4.83789ZM5.1084 4.52344H14.3984C14.7607 4.52344 15.0479 4.23633 15.0479 3.87402C15.0479 3.51172 14.7607 3.22461 14.3984 3.22461H5.1084C4.74609 3.22461 4.45898 3.51172 4.45898 3.87402C4.45898 4.23633 4.74609 4.52344 5.1084 4.52344ZM1.91602 9.03516C2.44238 9.03516 2.87305 8.60449 2.87305 8.07129C2.87305 7.54492 2.44238 7.11426 1.91602 7.11426C1.38281 7.11426 0.952148 7.54492 0.952148 8.07129C0.952148 8.60449 1.38281 9.03516 1.91602 9.03516ZM5.1084 8.7207H14.3984C14.7607 8.7207 15.0479 8.43359 15.0479 8.07129C15.0479 7.70898 14.7607 7.42188 14.3984 7.42188H5.1084C4.74609 7.42188 4.45898 7.70898 4.45898 8.07129C4.45898 8.43359 4.74609 8.7207 5.1084 8.7207ZM1.91602 13.2324C2.44238 13.2324 2.87305 12.8018 2.87305 12.2686C2.87305 11.7422 2.44238 11.3115 1.91602 11.3115C1.38281 11.3115 0.952148 11.7422 0.952148 12.2686C0.952148 12.8018 1.38281 13.2324 1.91602 13.2324ZM5.1084 12.918H14.3984C14.7607 12.918 15.0479 12.6309 15.0479 12.2686C15.0479 11.9062 14.7607 11.6191 14.3984 11.6191H5.1084C4.74609 11.6191 4.45898 11.9062 4.45898 12.2686C4.45898 12.6309 4.74609 12.918 5.1084 12.918Z"></path></svg></span>Multi-select</th><td></td></tr></tbody></table></header><div class="page-body"><h3 id="1b367645-92b5-8049-b643-cef36e902513" class=""><strong>Q1. How does Agglomerative Hierarchical Clustering Work? Explain with suitable diagrams.</strong></h3><p id="1b367645-92b5-802a-84eb-ff10ec616f0f" class="">Agglomerative Hierarchical Clustering (AHC) is a <strong>bottom-up clustering method</strong>, where each data point starts as its own cluster and iteratively merges with the nearest clusters until a single cluster remains.</p><h3 id="1b367645-92b5-80da-83da-cc01319102ef" class=""><strong>Steps of AHC:</strong></h3><ol type="1" id="1b367645-92b5-8069-9946-ec9ef1b9bdf9" class="numbered-list" start="1"><li><strong>Start with individual points</strong> as separate clusters.</li></ol><ol type="1" id="1b367645-92b5-8065-8c42-f960a6d51693" class="numbered-list" start="2"><li><strong>Compute pairwise distances</strong> between clusters (e.g., Euclidean distance).</li></ol><ol type="1" id="1b367645-92b5-8007-ac67-f53353f45e76" class="numbered-list" start="3"><li><strong>Merge the two closest clusters</strong> based on a linkage criterion.</li></ol><ol type="1" id="1b367645-92b5-8006-8fb5-c0117e58dac1" class="numbered-list" start="4"><li><strong>Repeat</strong> until all clusters are merged into one.</li></ol><h3 id="1b367645-92b5-80eb-885c-cdaad014d313" class=""><strong>Types of Linkage Methods in AHC:</strong></h3><ul id="1b367645-92b5-806b-b99f-ed83bffeffb7" class="bulleted-list"><li style="list-style-type:disc"><strong>Single Linkage:</strong> Minimum distance between clusters.</li></ul><ul id="1b367645-92b5-801a-af99-ebd44671cacd" class="bulleted-list"><li style="list-style-type:disc"><strong>Complete Linkage:</strong> Maximum distance between clusters.</li></ul><ul id="1b367645-92b5-80bc-9b71-cef291b0f5f1" class="bulleted-list"><li style="list-style-type:disc"><strong>Average Linkage:</strong> Average distance between all points in clusters.</li></ul><ul id="1b367645-92b5-803c-acaa-dfe1fcf52267" class="bulleted-list"><li style="list-style-type:disc"><strong>Centroid Linkage:</strong> Distance between centroids of clusters.</li></ul><h3 id="1b367645-92b5-804d-8d78-f42bc48898e0" class=""><strong>Diagram:</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-80dd-9255-f57b82f91995" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A1((A)) --&gt;|Merge| B((B))
    A2((B)) --&gt;|Merge| B
    A3((C)) --&gt;|Merge| C((C))
    A4((D)) --&gt;|Merge| C
    B --&gt;|Merge| D((D))
    C --&gt;|Merge| D
</code></pre><p id="1b367645-92b5-8096-9585-f133f997f1c5" class="">This represents the merging process in a hierarchical manner.</p><hr id="1b367645-92b5-8060-8d6e-d0dedb959017"/><h3 id="1b367645-92b5-8032-a3ba-e630db609428" class=""><strong>Q2. How is K-Nearest Neighbors (KNN) helpful to find the best suitable class for a new data point? Explain with algorithmic steps and diagrammatic representation.</strong></h3><p id="1b367645-92b5-8000-8e17-cd3d67606376" class="">K-Nearest Neighbors (KNN) is a <strong>lazy learning algorithm</strong> that classifies a new data point based on the <strong>majority class of its nearest neighbors</strong>.</p><h3 id="1b367645-92b5-800a-b9d4-f8735e4fbcec" class=""><strong>Algorithmic Steps:</strong></h3><ol type="1" id="1b367645-92b5-80a9-8407-f8d72665b772" class="numbered-list" start="1"><li><strong>Select the number of neighbors (K)</strong>.</li></ol><ol type="1" id="1b367645-92b5-808e-976b-dda68c3826d6" class="numbered-list" start="2"><li><strong>Compute the distance</strong> (e.g., Euclidean) between the new data point and existing points.</li></ol><ol type="1" id="1b367645-92b5-80ee-9cec-d6482439bd51" class="numbered-list" start="3"><li><strong>Sort the distances</strong> in ascending order.</li></ol><ol type="1" id="1b367645-92b5-80a2-af33-e1d55a5b62e5" class="numbered-list" start="4"><li><strong>Select the K closest neighbors</strong>.</li></ol><ol type="1" id="1b367645-92b5-8026-a3a6-ed8b3db4909b" class="numbered-list" start="5"><li><strong>Assign the most common class</strong> among the K neighbors to the new point.</li></ol><h3 id="1b367645-92b5-8034-b652-e4894ffda41f" class=""><strong>Diagram:</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-809e-a699-e36e23c65d9f" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A((New Data)) --&gt;|K=3 Neighbors| B1((Class A))
    A --&gt; B2((Class B))
    A --&gt; B3((Class A))
</code></pre><p id="1b367645-92b5-8035-b20e-fae821cd33dc" class="">If K=3 and two out of three closest points belong to Class A, the new point is classified as Class A.</p><hr id="1b367645-92b5-8074-bb31-d05c58d13967"/><h3 id="1b367645-92b5-8040-b303-fb8c0cdd1a0d" class=""><strong>Q3. How does SVM work for Linear and Non-Linear datasets? Explain with Diagrammatic representation.</strong></h3><p id="1b367645-92b5-8020-b6d3-dc8396d3c0fc" class=""><strong>Support Vector Machine (SVM)</strong> is a powerful supervised learning algorithm used for classification.</p><h3 id="1b367645-92b5-8023-b96b-c76980389b91" class=""><strong>Linear SVM:</strong></h3><ul id="1b367645-92b5-80f7-b723-f4836baaf3c3" class="bulleted-list"><li style="list-style-type:disc"><strong>Used when data is linearly separable</strong>.</li></ul><ul id="1b367645-92b5-80fd-bde6-e07c87baf008" class="bulleted-list"><li style="list-style-type:disc">Finds an optimal <strong>hyperplane</strong> that maximizes the margin between two classes.</li></ul><h3 id="1b367645-92b5-80cb-9c42-d853a0e3c352" class=""><strong>Non-Linear SVM:</strong></h3><ul id="1b367645-92b5-808e-b118-f8be90395713" class="bulleted-list"><li style="list-style-type:disc"><strong>Used when data is not linearly separable</strong>.</li></ul><ul id="1b367645-92b5-80a2-8811-d9aa59d7e628" class="bulleted-list"><li style="list-style-type:disc">Uses <strong>kernel functions</strong> (e.g., Polynomial, RBF) to transform data into higher dimensions.</li></ul><h3 id="1b367645-92b5-806b-891a-de0046bd5842" class=""><strong>Diagram:</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-8068-9f29-c8b1b6f4fcb5" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A((Class A)) ---|Hyperplane| B((Class B))
</code></pre><p id="1b367645-92b5-804b-9660-e56eca629359" class="">For non-linear data, the kernel trick helps in <strong>mapping data to a higher dimension</strong> to make it separable.</p><hr id="1b367645-92b5-804c-83db-f070ee1118a8"/><h3 id="1b367645-92b5-80c8-8083-d32621b3bab7" class=""><strong>Q4. What is Clustering? Explain Hierarchical Clustering with types.</strong></h3><p id="1b367645-92b5-809e-9111-c8380f20b99b" class=""><strong>Clustering</strong> is an <strong>unsupervised learning technique</strong> used to group similar data points.</p><h3 id="1b367645-92b5-807f-8e50-c8101a1fb1a3" class=""><strong>Hierarchical Clustering Types:</strong></h3><ol type="1" id="1b367645-92b5-8006-be48-f013b499d60b" class="numbered-list" start="1"><li><strong>Agglomerative Clustering</strong> â€“ Bottom-up approach (merging clusters).</li></ol><ol type="1" id="1b367645-92b5-8027-bf85-d97de309b770" class="numbered-list" start="2"><li><strong>Divisive Clustering</strong> â€“ Top-down approach (splitting clusters).</li></ol><p id="1b367645-92b5-8050-b63f-f43e03440ecd" class="">Hierarchical clustering provides a <strong>dendrogram</strong>, which helps in choosing the optimal number of clusters.</p><hr id="1b367645-92b5-80ac-8adb-cb1303c58f8d"/><h3 id="1b367645-92b5-8062-b3a2-d29f45727158" class=""><strong>Q5. How is KNN helpful for image classification?</strong></h3><ul id="1b367645-92b5-80f8-b8c0-f950431b140c" class="bulleted-list"><li style="list-style-type:disc">KNN can classify images by <strong>comparing pixel intensities</strong>.</li></ul><ul id="1b367645-92b5-8096-aebc-c8b34aa04c39" class="bulleted-list"><li style="list-style-type:disc">Works well when images have <strong>low feature complexity</strong>.</li></ul><ul id="1b367645-92b5-805c-ad50-d837adac73ba" class="bulleted-list"><li style="list-style-type:disc">The <strong>distance metric</strong> (e.g., Euclidean) determines similarity.</li></ul><ul id="1b367645-92b5-8009-afd5-fa2510ebe730" class="bulleted-list"><li style="list-style-type:disc">Requires <strong>preprocessing</strong> like feature extraction (HOG, SIFT).</li></ul><hr id="1b367645-92b5-80d5-bbc1-cf5f0e379b27"/><h3 id="1b367645-92b5-801b-8991-f0905ccf7490" class=""><strong>Q6. Calculate the value for m and b for the formula y=mx+b</strong></h3><p id="1b367645-92b5-80d9-bfc1-e9d9074b35f2" class="">Given data:</p><ul id="1b367645-92b5-80cd-aa5c-cc042d7a857a" class="bulleted-list"><li style="list-style-type:disc"><strong>x:</strong> 1, 2, 3, 4, 5</li></ul><ul id="1b367645-92b5-8046-a290-ca50f397c653" class="bulleted-list"><li style="list-style-type:disc"><strong>y:</strong> 2, 5, 3, 8, 7</li></ul><figure id="1b367645-92b5-8005-892f-e22b6f8d5799" class="image"><a href="Unit%203%201b36764592b58097beeaea161d2a93a9/image.png"><img style="width:533px" src="Unit%203%201b36764592b58097beeaea161d2a93a9/image.png"/></a></figure><hr id="1b367645-92b5-8026-9267-ef81afa80b27"/><h3 id="1b367645-92b5-80d4-8b42-c66cbee96b9c" class=""><strong>Q7. What is Multivariate Regression? How does it differ from Simple Regression? Give an example.</strong></h3><h3 id="1b367645-92b5-80ce-af64-ea36bb0ddfe1" class=""><strong>Simple Regression:</strong></h3><ul id="1b367645-92b5-8073-8282-fff231d85b5b" class="bulleted-list"><li style="list-style-type:disc"><strong>One independent variable (X)</strong>.</li></ul><ul id="1b367645-92b5-80be-be59-eaa6b667a453" class="bulleted-list"><li style="list-style-type:disc">Example: Predicting house price based on <strong>area</strong>.</li></ul><h3 id="1b367645-92b5-807c-ab35-dd8928e67f34" class=""><strong>Multivariate Regression:</strong></h3><ul id="1b367645-92b5-8065-b17c-e69d30f7cdd5" class="bulleted-list"><li style="list-style-type:disc"><strong>Multiple independent variables</strong>.</li></ul><ul id="1b367645-92b5-8082-9a97-cba4c13a04b1" class="bulleted-list"><li style="list-style-type:disc">Example: Predicting house price based on <strong>area, location, number of bedrooms</strong>.</li></ul><p id="1b367645-92b5-80c3-beaa-c2d9435b1265" class="">Formula:</p><figure id="1b367645-92b5-8037-a6d4-e2b52d238ded" class="image"><a href="Unit%203%201b36764592b58097beeaea161d2a93a9/image%201.png"><img style="width:338px" src="Unit%203%201b36764592b58097beeaea161d2a93a9/image%201.png"/></a></figure><hr id="1b367645-92b5-80c6-adf5-c7d074efcec8"/><h3 id="1b367645-92b5-8057-b018-cccb0df31400" class=""><strong>Q9. How is Least Squares Regression helpful for classification? Explain with formula and example.</strong></h3><p id="1b367645-92b5-8097-b975-c078597cd204" class="">Least Squares Regression can be <strong>used for classification</strong> by fitting a linear boundary.</p><figure id="1b367645-92b5-806e-921d-ff7256ddef3b" class="image"><a href="Unit%203%201b36764592b58097beeaea161d2a93a9/image%202.png"><img style="width:552.984375px" src="Unit%203%201b36764592b58097beeaea161d2a93a9/image%202.png"/></a></figure><p id="1b367645-92b5-80f6-89f9-c70325159dc6" class="">Example:</p><ul id="1b367645-92b5-80ce-84a3-db0d93872459" class="bulleted-list"><li style="list-style-type:disc">Predict <strong>spam (1) or not spam (0)</strong> based on email features.</li></ul><hr id="1b367645-92b5-80c4-b3d0-f90846f15e7d"/><h3 id="1b367645-92b5-8092-aea8-dcb5e1cb651d" class=""><strong>Q8. Enlist the various Distance-Based Algorithms and Compare Them with Graphical Representation.</strong></h3><h3 id="1b367645-92b5-8064-bd8c-d6ad67252e01" class=""><strong>Distance-Based Algorithms</strong></h3><p id="1b367645-92b5-8046-8661-d3009bf9437e" class="">Distance-based algorithms rely on measuring the similarity or difference between data points based on a chosen distance metric (e.g., Euclidean, Manhattan, Minkowski). Some of the key distance-based algorithms include:</p><ol type="1" id="1b367645-92b5-801c-a245-cfe6a792fb1a" class="numbered-list" start="1"><li><strong>K-Nearest Neighbors (KNN)</strong><ul id="1b367645-92b5-80d0-873a-e104a3900866" class="bulleted-list"><li style="list-style-type:disc">A supervised learning algorithm used for classification and regression.</li></ul><ul id="1b367645-92b5-8089-9047-c95da91c6533" class="bulleted-list"><li style="list-style-type:disc">Classifies a new data point based on the majority class among its K-nearest neighbors.</li></ul><ul id="1b367645-92b5-8052-85a7-d6bc42280814" class="bulleted-list"><li style="list-style-type:disc"><strong>Distance Metric:</strong> Euclidean, Manhattan, Minkowski.</li></ul></li></ol><ol type="1" id="1b367645-92b5-805a-bbeb-ede6032355b5" class="numbered-list" start="2"><li><strong>K-Means Clustering</strong><ul id="1b367645-92b5-80d8-b80c-f92f89fc2d02" class="bulleted-list"><li style="list-style-type:disc">An unsupervised learning algorithm that partitions data into K clusters.</li></ul><ul id="1b367645-92b5-8092-9f6f-ec713df62933" class="bulleted-list"><li style="list-style-type:disc">Assigns each data point to the nearest cluster centroid and updates centroids iteratively.</li></ul><ul id="1b367645-92b5-8068-8418-f2e19cc75f2e" class="bulleted-list"><li style="list-style-type:disc"><strong>Distance Metric:</strong> Euclidean distance is commonly used.</li></ul></li></ol><ol type="1" id="1b367645-92b5-80e3-bea3-f7570e6e4214" class="numbered-list" start="3"><li><strong>Hierarchical Clustering</strong><ul id="1b367645-92b5-80fa-88c8-fbaf8e17c605" class="bulleted-list"><li style="list-style-type:disc">An unsupervised learning algorithm that forms a hierarchy of clusters.</li></ul><ul id="1b367645-92b5-80e6-b199-de29dabf22ed" class="bulleted-list"><li style="list-style-type:disc">Uses <strong>Agglomerative</strong> (bottom-up) or <strong>Divisive</strong> (top-down) approaches.</li></ul><ul id="1b367645-92b5-8068-a68b-d38b9c3492ce" class="bulleted-list"><li style="list-style-type:disc"><strong>Distance Metric:</strong> Euclidean, Cosine, Manhattan.</li></ul></li></ol><ol type="1" id="1b367645-92b5-803d-b602-d77b71a472b5" class="numbered-list" start="4"><li><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</strong><ul id="1b367645-92b5-8031-a8fe-ca649c7b3e06" class="bulleted-list"><li style="list-style-type:disc">Groups data points based on density, making it effective for arbitrary-shaped clusters.</li></ul><ul id="1b367645-92b5-805c-8c43-f1f9d8bdbb97" class="bulleted-list"><li style="list-style-type:disc">Differentiates between core points, border points, and noise.</li></ul><ul id="1b367645-92b5-808c-acf7-d4cdee90e6b9" class="bulleted-list"><li style="list-style-type:disc"><strong>Distance Metric:</strong> Euclidean distance.</li></ul></li></ol><h3 id="1b367645-92b5-803c-a71b-c94dd7a67908" class=""><strong>Graphical Comparison</strong></h3><h3 id="1b367645-92b5-803d-b23a-c2b0bae63591" class=""><strong>1. K-Nearest Neighbors (KNN) Classification</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-8089-a29d-f65cbf5be185" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A((New Data)) --&gt;|K=3 Neighbors| B1((Class A))
    A --&gt; B2((Class B))
    A --&gt; B3((Class A))
</code></pre><p id="1b367645-92b5-808a-8e62-e838bcaf26be" class=""><strong>Interpretation:</strong> If K=3 and two out of three neighbors belong to Class A, the new data point is classified as Class A.</p><h3 id="1b367645-92b5-8024-a4f7-c3d6ca5eb84b" class=""><strong>2. K-Means Clustering</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-80b4-a943-eeca075ec364" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A1((Cluster 1)) --&gt;|Centroid| C1((C1))
    A2((Cluster 2)) --&gt;|Centroid| C2((C2))
    A3((Cluster 3)) --&gt;|Centroid| C3((C3))
</code></pre><p id="1b367645-92b5-8016-b3b1-f1c1bd42bfb0" class=""><strong>Interpretation:</strong> Data points are assigned to the nearest centroid, and centroids are updated iteratively.</p><h3 id="1b367645-92b5-80e9-91d8-d00fb95b87e5" class=""><strong>3. Hierarchical Clustering (Dendrogram Representation)</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-80a7-a024-e2af196cf636" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A1((A)) --&gt;|Merge| B((B))
    A2((B)) --&gt;|Merge| B
    A3((C)) --&gt;|Merge| C((C))
    A4((D)) --&gt;|Merge| C
    B --&gt;|Merge| D((D))
    C --&gt;|Merge| D
</code></pre><p id="1b367645-92b5-805d-9165-ca27a2c4c516" class=""><strong>Interpretation:</strong> The merging process continues until all clusters combine into one.</p><h3 id="1b367645-92b5-80f1-8e03-dab4445cada9" class=""><strong>4. DBSCAN (Density-Based Clustering)</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b367645-92b5-8045-86b5-c95e151919fb" class="code"><code class="language-Mermaid" style="white-space:pre-wrap;word-break:break-all">graph TD;
    A((Core Point)) --&gt;|Dense Region| B((Cluster Formed))
    C((Border Point)) --&gt;|Noise| D((Outlier))
</code></pre><p id="1b367645-92b5-804b-ae5f-c7a03fd630d2" class=""><strong>Interpretation:</strong> DBSCAN groups dense regions and identifies outliers as noise.</p><hr id="1b367645-92b5-8069-845a-d5c457fc6c0e"/><h3 id="1b367645-92b5-803f-ad60-cc48b6e5d43f" class=""><strong>Comparison Table</strong></h3><table id="1b367645-92b5-8055-905f-e86b0a95be92" class="simple-table"><tbody><tr id="1b367645-92b5-802b-9938-e51053f196e5"><td id="eoGT" class="">Algorithm</td><td id="YO:r" class="">Type</td><td id="Nqa?" class="">Distance Metric</td><td id="ya]q" class="">Strength</td><td id="Qi\?" class="">Weakness</td></tr><tr id="1b367645-92b5-8031-a1c0-c601d3c5dff7"><td id="eoGT" class="">KNN</td><td id="YO:r" class="">Supervised</td><td id="Nqa?" class="">Euclidean, Manhattan</td><td id="ya]q" class="">Simple, effective</td><td id="Qi\?" class="">Slow for large datasets</td></tr><tr id="1b367645-92b5-805b-b8ae-c192ce97fdba"><td id="eoGT" class="">K-Means</td><td id="YO:r" class="">Unsupervised</td><td id="Nqa?" class="">Euclidean</td><td id="ya]q" class="">Fast, easy to interpret</td><td id="Qi\?" class="">Requires predefined K</td></tr><tr id="1b367645-92b5-808f-b338-eb693bca9bcf"><td id="eoGT" class="">Hierarchical</td><td id="YO:r" class="">Unsupervised</td><td id="Nqa?" class="">Euclidean, Manhattan</td><td id="ya]q" class="">No need for K</td><td id="Qi\?" class="">Computationally expensive</td></tr><tr id="1b367645-92b5-80da-b630-c223a69fb274"><td id="eoGT" class="">DBSCAN</td><td id="YO:r" class="">Unsupervised</td><td id="Nqa?" class="">Euclidean</td><td id="ya]q" class="">Handles noise and complex shapes</td><td id="Qi\?" class="">Sensitive to parameters</td></tr></tbody></table><p id="1b367645-92b5-8020-be8e-d326d73495d5" class="">This comparison highlights the strengths and weaknesses of different distance-based algorithms. ðŸš€</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>